import streamlit as st 
import chat
import json
import knowledge_base as kb
import cost_analysis as cost
import supervisor
import router
import swarm
import traceback
import mcp_config 
import logging
import utils
import sys
import os

logging.basicConfig(
    level=logging.INFO,  # Default to INFO level
    format='%(filename)s:%(lineno)d | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("streamlit")

# í˜„ì¬ ì‚¬ìš©ì ì •ë³´ í™•ì¸
current_user = os.getlogin()
logger.info(f"Current user: {current_user}")




# title
st.set_page_config(page_title='MCP', page_icon=None, layout="centered", initial_sidebar_state="auto", menu_items=None)

# CSS for adjusting sidebar width
st.markdown("""
    <style>
    [data-testid="stSidebar"][aria-expanded="true"] {
        width: 400px !important;
    }
    </style>
""", unsafe_allow_html=True)

mode_descriptions = {
    "ì¼ìƒì ì¸ ëŒ€í™”": [
        "ëŒ€í™”ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±—ë´‡ê³¼ ì¼ìƒì˜ ëŒ€í™”ë¥¼ í¸ì•ˆíˆ ì¦ê¸¸ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "RAG": [
        "Bedrock Knowledge Baseë¥¼ ì´ìš©í•´ êµ¬í˜„í•œ RAGë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    ],
    "Agent": [
        "MCPë¥¼ í™œìš©í•œ Agentë¥¼ ì´ìš©í•©ë‹ˆë‹¤. ì™¼ìª½ ë©”ë‰´ì—ì„œ í•„ìš”í•œ MCPë¥¼ ì„ íƒí•˜ì„¸ìš”."
    ],
    "Agent (Chat)": [
        "MCPë¥¼ í™œìš©í•œ Agentë¥¼ ì´ìš©í•©ë‹ˆë‹¤. ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ì´ìš©í•´ interativeí•œ ëŒ€í™”ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "Multi-agent Supervisor (Router)": [
        "Multi-agent Supervisor (Router)ì— ê¸°ë°˜í•œ ëŒ€í™”ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” Supervisor/Collaboratorsì˜ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
    ],
    "LangGraph Supervisor": [
        "LangGraph Supervisorë¥¼ ì´ìš©í•œ Multi-agent Collaborationì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” Supervisor/Collaboratorsì˜ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
    ],
    "LangGraph Swarm": [
        "LangGraph Swarmë¥¼ ì´ìš©í•œ Multi-agent Collaborationì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” Agentë“¤ ì‚¬ì´ì— ì„œë¡œ ì •ë³´ë¥¼ êµí™˜í•©ë‹ˆë‹¤."
    ],
    "ë²ˆì—­í•˜ê¸°": [
        "í•œêµ­ì–´ì™€ ì˜ì–´ì— ëŒ€í•œ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ, ì˜ì–´ë¡œ ì…ë ¥í•˜ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."        
    ],
    "ë¬¸ë²• ê²€í† í•˜ê¸°": [
        "ì˜ì–´ì™€ í•œêµ­ì–´ ë¬¸ë²•ì˜ ë¬¸ì œì ì„ ì„¤ëª…í•˜ê³ , ìˆ˜ì •ëœ ê²°ê³¼ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤."
    ],
    "ì´ë¯¸ì§€ ë¶„ì„": [
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "ë¹„ìš© ë¶„ì„": [
        "Cloud ì‚¬ìš©ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
    ]
}

def load_image_generator_config():
    config = None
    try:
        with open("image_generator_config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
            logger.info(f"loaded image_generator_config: {config}")
    except FileNotFoundError:
        config = {"seed_image": ""}
        with open("image_generator_config.json", "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=4)
        logger.info("Create new image_generator_config.json")
    except Exception:
        err_msg = traceback.format_exc()
        logger.info(f"error message: {err_msg}")    
    return config

def update_seed_image_url(url):
    with open("image_generator_config.json", "w", encoding="utf-8") as f:
        config = {"seed_image": url}
        json.dump(config, f, ensure_ascii=False, indent=4)

seed_config = load_image_generator_config()
logger.info(f"seed_config: {seed_config}")
seed_image_url = seed_config.get("seed_image", "") if seed_config else ""
logger.info(f"seed_image_url from config: {seed_image_url}")

uploaded_seed_image = None
with st.sidebar:
    st.title("ğŸ”® Menu")
    
    st.markdown(
        "Amazon Bedrockì„ ì´ìš©í•´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤." 
        "ì—¬ê¸°ì—ì„œëŠ” MCPë¥¼ ì´ìš©í•´ RAGë¥¼ êµ¬í˜„í•˜ê³ , Multi agentë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." 
        "ë˜í•œ ë²ˆì—­ì´ë‚˜ ë¬¸ë²• í™•ì¸ê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        "ì£¼ìš” ì½”ë“œëŠ” LangChainê³¼ LangGraphë¥¼ ì´ìš©í•´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        "ìƒì„¸í•œ ì½”ë“œëŠ” [Github](https://github.com/kyopark2014/mcp)ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    )

    st.subheader("ğŸ± ëŒ€í™” í˜•íƒœ")
    
    # radio selection
    mode = st.radio(
        label="ì›í•˜ëŠ” ëŒ€í™” í˜•íƒœë¥¼ ì„ íƒí•˜ì„¸ìš”. ",options=["ì¼ìƒì ì¸ ëŒ€í™”", "RAG", "Agent", "Agent (Chat)", "Multi-agent Supervisor (Router)", "LangGraph Supervisor", "LangGraph Swarm", "ë²ˆì—­í•˜ê¸°", "ë¬¸ë²• ê²€í† í•˜ê¸°", "ì´ë¯¸ì§€ ë¶„ì„", "ë¹„ìš© ë¶„ì„"], index=2
    )   
    st.info(mode_descriptions[mode][0])
    
    # mcp selection
    mcp = ""
    if mode=='Agent' or mode=='Agent (Chat)':
        # MCP Config JSON input
        st.subheader("âš™ï¸ MCP Config")

        # Change radio to checkbox
        mcp_options = [
            "default", "code interpreter", "aws document", "aws cost", "aws cli", 
            "aws cloudwatch", "aws storage", "image generation", "aws diagram",
            "knowledge base", "tavily", "perplexity", "ArXiv", "wikipedia", 
            "filesystem", "terminal", "text editor", "context7", "puppeteer", 
            "playwright", "firecrawl", "obsidian", "airbnb", "ì‚¬ìš©ì ì„¤ì •"
        ]
        # mcp_options = [ 
        #     "default", "code interpreter", "aws document", "aws cost", "aws cli", 
        #     "aws cloudwatch", "aws storage", "image generation",
        #     "knowledge base", "tavily", "ArXiv", "wikipedia", 
        #     "filesystem", "terminal", "text editor", 
        #     "playwright", "firecrawl", "airbnb", "ì‚¬ìš©ì ì„¤ì •"
        # ]
        mcp_selections = {}
        default_selections = ["default", "tavily", "aws cli", "code interpreter"]

        with st.expander("MCP ì˜µì…˜ ì„ íƒ", expanded=True):            
            # Create two columns
            col1, col2 = st.columns(2)
            
            # Split options into two groups
            mid_point = len(mcp_options) // 2
            first_half = mcp_options[:mid_point]
            second_half = mcp_options[mid_point:]
            
            # Display first group in the first column
            with col1:
                for option in first_half:
                    default_value = option in default_selections
                    mcp_selections[option] = st.checkbox(option, key=f"mcp_{option}", value=default_value)
            
            # Display second group in the second column
            with col2:
                for option in second_half:
                    default_value = option in default_selections
                    mcp_selections[option] = st.checkbox(option, key=f"mcp_{option}", value=default_value)
        
        if not any(mcp_selections.values()):
            mcp_selections["default"] = True

        if mcp_selections["ì‚¬ìš©ì ì„¤ì •"]:
            mcp_info = st.text_area(
                "MCP ì„¤ì •ì„ JSON í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”",
                value=mcp,
                height=150
            )
            logger.info(f"mcp_info: {mcp_info}")

            if mcp_info:
                mcp_config.mcp_user_config = json.loads(mcp_info)
                logger.info(f"mcp_user_config: {mcp_config.mcp_user_config}")
        
        if mcp_selections["image generation"]:
            enable_seed = st.checkbox("Seed Image", value=False)

            if enable_seed:
                st.subheader("ğŸŒ‡ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                uploaded_seed_image = st.file_uploader("ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["png", "jpg", "jpeg"])

                if uploaded_seed_image:
                    url = chat.upload_to_s3(uploaded_seed_image.getvalue(), uploaded_seed_image.name)
                    logger.info(f"uploaded url: {url}")
                    seed_image_url = url
                    update_seed_image_url(seed_image_url)
                
                given_image_url = st.text_input("ë˜ëŠ” ì´ë¯¸ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”", value=seed_image_url, key="seed_image_input")       
                if given_image_url and given_image_url != seed_image_url:       
                    logger.info(f"given_image_url: {given_image_url}")
                    seed_image_url = given_image_url
                    update_seed_image_url(seed_image_url)                    
            else:
                if seed_image_url:
                    logger.info(f"remove seed_image_url")
                    update_seed_image_url("") 
        else:
            enable_seed = False
            if seed_image_url:
                logger.info(f"remove seed_image_url")
                update_seed_image_url("") 

        mcp = mcp_config.load_selected_config(mcp_selections)
        # logger.info(f"mcp: {mcp}")

    # model selection box
    modelName = st.selectbox(
        'ğŸ–Šï¸ ì‚¬ìš© ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”',
        ("Nova Premier", 'Nova Pro', 'Nova Lite', 'Nova Micro', 'Claude 4 Opus', 'Claude 4 Sonnet', 'Claude 3.7 Sonnet', 'Claude 3.5 Sonnet', 'Claude 3.0 Sonnet', 'Claude 3.5 Haiku'), index=7
    )

    # debug checkbox
    select_debugMode = st.checkbox('Debug Mode', value=True)
    debugMode = 'Enable' if select_debugMode else 'Disable'
    #print('debugMode: ', debugMode)

    # multi region check box
    select_multiRegion = st.checkbox('Multi Region', value=False)
    multiRegion = 'Enable' if select_multiRegion else 'Disable'
    #print('multiRegion: ', multiRegion)

    # extended thinking of claude 3.7 sonnet
    select_reasoning = st.checkbox('Reasoning', value=False)
    reasoningMode = 'Enable' if select_reasoning else 'Disable'
    # logger.info(f"reasoningMode: {reasoningMode}")

    uploaded_file = None
    if mode=='ì´ë¯¸ì§€ ë¶„ì„':
        st.subheader("ğŸŒ‡ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ìš”ì•½ì„ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["png", "jpg", "jpeg"])
    elif mode=='RAG' or mode=="Agent" or mode=="Agent (Chat)":
        st.subheader("ğŸ“‹ ë¬¸ì„œ ì—…ë¡œë“œ")
        # print('fileId: ', chat.fileId)
        uploaded_file = st.file_uploader("RAGë¥¼ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["pdf", "txt", "py", "md", "csv", "json"], key=chat.fileId)

    chat.update(modelName, debugMode, multiRegion, mcp, reasoningMode)

    st.success(f"Connected to {modelName}", icon="ğŸ’š")
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear")
    # logger.info(f"clear_button: {clear_button}")

st.title('ğŸ”® '+ mode)

if clear_button==True:
    chat.initiate()
    cost.cost_data = {}
    cost.visualizations = {}

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.greetings = False

# Display chat messages from history on app rerun
def display_chat_messages() -> None:
    """Print message history
    @returns None
    """
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if "images" in message:                
                for url in message["images"]:
                    logger.info(f"url: {url}")

                    file_name = url[url.rfind('/')+1:]
                    st.image(url, caption=file_name, use_container_width=True)
            st.markdown(message["content"])

display_chat_messages()

def show_references(reference_docs):
    if debugMode == "Enable" and reference_docs:
        with st.expander(f"ë‹µë³€ì—ì„œ ì°¸ì¡°í•œ {len(reference_docs)}ê°œì˜ ë¬¸ì„œì…ë‹ˆë‹¤."):
            for i, doc in enumerate(reference_docs):
                st.markdown(f"**{doc.metadata['name']}**: {doc.page_content}")
                st.markdown("---")

# Greet user
if not st.session_state.greetings:
    with st.chat_message("assistant"):
        intro = "ì•„ë§ˆì¡´ ë² ë“œë½ì„ ì´ìš©í•˜ì—¬ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ëŒ€í™”ë¥¼ ì¦ê¸°ì‹¤ìˆ˜ ìˆìœ¼ë©°, íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìš”ì•½ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.markdown(intro)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": intro})
        st.session_state.greetings = True

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    uploaded_file = None
    
    st.session_state.greetings = False
    chat.clear_chat_history()
    st.rerun()    

# Preview the uploaded image in the sidebar
file_name = ""
state_of_code_interpreter = False
if uploaded_file is not None and clear_button==False:
    logger.info(f"uploaded_file.name: {uploaded_file.name}")
    if uploaded_file.name:
        logger.info(f"csv type? {uploaded_file.name.lower().endswith(('.csv'))}")

    if uploaded_file.name and not mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        chat.initiate()

        if debugMode=='Enable':
            status = 'ì„ íƒí•œ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.'
            logger.info(f"status: {status}")
            st.info(status)

        file_name = uploaded_file.name
        logger.info(f"uploading... file_name: {file_name}")
        file_url = chat.upload_to_s3(uploaded_file.getvalue(), file_name)
        logger.info(f"file_url: {file_url}")

        kb.sync_data_source()  # sync uploaded files
            
        status = f'ì„ íƒí•œ "{file_name}"ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.'
        # my_bar = st.sidebar.progress(0, text=status)
        
        # for percent_complete in range(100):
        #     time.sleep(0.2)
        #     my_bar.progress(percent_complete + 1, text=status)
        if debugMode=='Enable':
            logger.info(f"status: {status}")
            st.info(status)
    
        msg = chat.get_summary_of_uploaded_file(file_name, st)
        st.session_state.messages.append({"role": "assistant", "content": f"ì„ íƒí•œ ë¬¸ì„œ({file_name})ë¥¼ ìš”ì•½í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n\n{msg}"})    
        logger.info(f"msg: {msg}")

        st.write(msg)

    if uploaded_file and clear_button==False and mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        st.image(uploaded_file, caption="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)

        file_name = uploaded_file.name
        url = chat.upload_to_s3(uploaded_file.getvalue(), file_name)
        logger.info(f"url: {url}")

if seed_image_url and clear_button==False and enable_seed==True:
    st.image(seed_image_url, caption="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)
    logger.info(f"preview: {seed_image_url}")
    
if clear_button==False and mode == 'ë¹„ìš© ë¶„ì„':
    st.subheader("ğŸ“ˆ Cost Analysis")

    if not cost.visualizations:
        cost.get_visualiation()

    if 'service_pie' in cost.visualizations:
        st.plotly_chart(cost.visualizations['service_pie'])
    if 'daily_trend' in cost.visualizations:
        st.plotly_chart(cost.visualizations['daily_trend'])
    if 'region_bar' in cost.visualizations:
        st.plotly_chart(cost.visualizations['region_bar'])

    with st.status("thinking...", expanded=True, state="running") as status:
        if not cost.cost_data:
            st.info("ë¹„ìš© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            cost_data = cost.get_cost_analysis()
            logger.info(f"cost_data: {cost_data}")
            cost.cost_data = cost_data
        else:
            if not cost.insights:        
                st.info("ì ì‹œë§Œ ê¸°ë‹¤ë¦¬ì„¸ìš”. ì§€ë‚œ í•œë‹¬ê°„ì˜ ì‚¬ìš©ëŸ‰ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                insights = cost.generate_cost_insights()
                logger.info(f"insights: {insights}")
                cost.insights = insights
            
            st.markdown(cost.insights)
            st.session_state.messages.append({"role": "assistant", "content": cost.insights})

# Always show the chat input
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):  # display user message in chat message container
        st.markdown(prompt)

    st.session_state.messages.append({"role": "user", "content": prompt})  # add user message to chat history
    prompt = prompt.replace('"', "").replace("'", "")

    with st.chat_message("assistant"):
        if mode == 'ì¼ìƒì ì¸ ëŒ€í™”':
            stream = chat.general_conversation(prompt)            
            response = st.write_stream(stream)
            logger.info(f"response: {response}")
            st.session_state.messages.append({"role": "assistant", "content": response})

            chat.save_chat_history(prompt, response)

        elif mode == 'RAG':
            with st.status("running...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_rag_with_knowledge_base(prompt, st)                           
                st.write(response)
                logger.info(f"response: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
        
        elif mode == 'Agent':
            sessionState = ""
            chat.references = []
            chat.image_url = []
            response = chat.run_agent(prompt, "Disable", st)

        elif mode == 'Agent (Chat)':
            sessionState = ""
            chat.references = []
            chat.image_url = []
            response = chat.run_agent(prompt, "Enable", st)

        elif mode == "Multi-agent Supervisor (Router)":
            sessionState = ""
            chat.references = []
            chat.image_url = []
            with st.status("thinking...", expanded=True, state="running") as status:
                response, image_url, reference_docs = router.run_router_supervisor(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "images": image_url if image_url else []
                })
                chat.save_chat_history(prompt, response)       

                show_references(reference_docs)              

        elif mode == "LangGraph Supervisor":
            sessionState = ""
            chat.references = []
            chat.image_url = []
            with st.status("thinking...", expanded=True, state="running") as status:
                response, image_url, reference_docs = supervisor.run_langgraph_supervisor(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "images": image_url if image_url else []
                })
                chat.save_chat_history(prompt, response)       

                show_references(reference_docs)              

        elif mode == "LangGraph Swarm":
            sessionState = ""
            with st.status("thinking...", expanded=True, state="running") as status:
                response, image_url, reference_docs = swarm.run_langgraph_swarm(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "images": image_url if image_url else []
                })
                chat.save_chat_history(prompt, response)       

                show_references(reference_docs)              

        elif mode == 'ë²ˆì—­í•˜ê¸°':
            response = chat.translate_text(prompt)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)

        elif mode == 'ë¬¸ë²• ê²€í† í•˜ê¸°':
            response = chat.check_grammer(prompt)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)
        
        elif mode == 'ì´ë¯¸ì§€ ë¶„ì„':
            if uploaded_file is None or uploaded_file == "":
                st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                st.stop()

            else:
                if modelName == "Claude 3.5 Haiku":
                    st.error("Claude 3.5 Haikuì€ ì´ë¯¸ì§€ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                else:
                    with st.status("thinking...", expanded=True, state="running") as status:
                        summary = chat.get_image_summarization(file_name, prompt, st)
                        st.write(summary)

                        st.session_state.messages.append({"role": "assistant", "content": summary})

        elif mode == 'ë¹„ìš© ë¶„ì„':
            with st.status("thinking...", expanded=True, state="running") as status:
                response = cost.ask_cost_insights(prompt)
                st.write(response)

                st.session_state.messages.append({"role": "assistant", "content": response})

        else:
            stream = chat.general_conversation(prompt)

            response = st.write_stream(stream)
            logger.info(f"response: {response}")

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)
        


